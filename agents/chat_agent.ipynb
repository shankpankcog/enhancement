{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbc6c27c-8f83-467e-8700-10ff42570cf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow openai databricks-agents uv\n",
    "%pip install -U -qqqq botocore==1.37.11 s3transfer==0.11.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c402777-79ea-4cac-b8b2-dd1a16f2d357",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "from typing import Any, Generator, Optional\n",
    "from uuid import uuid4\n",
    "\n",
    "import mlflow\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from mlflow.entities import SpanType\n",
    "from mlflow.pyfunc.model import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "mlflow.openai.autolog()\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "\n",
    "class CustomChatAgent(ChatAgent):\n",
    "    def __init__(self):\n",
    "        self.workspace_client = WorkspaceClient()\n",
    "        self.client = self.workspace_client.serving_endpoints.get_open_ai_client()\n",
    "        self.llm_endpoint = LLM_ENDPOINT_NAME\n",
    "\n",
    "    def prepare_messages_for_llm(self, messages: list[ChatAgentMessage]) -> list[dict[str, Any]]:\n",
    "        \"\"\"Filter out ChatAgentMessage fields that are not compatible with LLM message formats\"\"\"\n",
    "        compatible_keys = [\"role\", \"content\", \"name\", \"tool_calls\", \"tool_call_id\"]\n",
    "        return [\n",
    "            {k: v for k, v in m.model_dump_compat(exclude_none=True).items() if k in compatible_keys} for m in messages\n",
    "        ]\n",
    "\n",
    "    #@mlflow.trace(span_type=SpanType.AGENT)\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None\n",
    "    ) -> ChatAgentResponse:\n",
    "        fixed_prompt = \"You're and AI assistant, users will provide the process deviation or process SOP related paragraphs from those Identify the most important keywords  and generate a concise, 10-12 word title that includes keywords.that includes them without adding additional notes or explanations Ensure to include any of the following keywords if they appear: SOP, TM-, KG, GMP (maintain original capitalization).  Adopt a formal, business-appropriate tone, Additionally, respond politely to users if they greet you, but focus on delivering high-quality service. Provide only the top 4 suggestions.\"\n",
    "\n",
    "        messages.insert(0, ChatAgentMessage(role=\"system\", content=fixed_prompt))\n",
    "\n",
    "        resp = self.client.chat.completions.create(\n",
    "            model=self.llm_endpoint,\n",
    "            messages=self.prepare_messages_for_llm(messages),\n",
    "        )\n",
    "\n",
    "        return ChatAgentResponse(\n",
    "            messages=[ChatAgentMessage(**resp.choices[0].message.to_dict(), id=str(uuid4()))],\n",
    "        )\n",
    "\n",
    "\n",
    "from mlflow.models import set_model\n",
    "\n",
    "AGENT = CustomChatAgent()\n",
    "set_model(AGENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f295803c-2133-4141-b4b3-ac09b4b02ffa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.types.agent import ChatAgentMessage\n",
    "from agent import AGENT\n",
    "\n",
    "# Define your question or message\n",
    "user_message = ChatAgentMessage(\n",
    "    role=\"user\",\n",
    "    content=\"Collaboration is a partnership; a union; the act of producing or making something together. Collaboration can take place between two people or many people, strangers or best friends. To collaborate is to commit to the possibility of producing an outcome greater than one that would be developed in a silo.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    # Call the predict method with your message\n",
    "    response = AGENT.predict(messages=[user_message])\n",
    "\n",
    "    # Print the response\n",
    "    if response and response.messages:\n",
    "        for message in response.messages:\n",
    "            print(f\"{message.role}: {message.content}\")\n",
    "    else:\n",
    "        print(\"No response received from the agent.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "043ad1b4-0af6-4993-af5c-0c7dd2185f56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b4a2cba-c42c-4ed6-b6c7-9d3aa0823baa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME\n",
    "from mlflow.models.resources import DatabricksServingEndpoint\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"openai\",\n",
    "            \"databricks-sdk\",\n",
    "        ],\n",
    "        resources=[DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c27a230b-ca5d-4622-bd6b-1bd69979ba6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d06d9a8c-b79f-408c-a841-abc50df330dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"pdm-pdm-dl-quality-docs-genai-dev\"\n",
    "schema = \"gvault_test\"\n",
    "model_name = \"agent1\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "211d696f-169d-44cf-bfb6-27e91829c53f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version,scale_to_zero=True, tags={\"manual\": \"testing\"})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "chat_agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
